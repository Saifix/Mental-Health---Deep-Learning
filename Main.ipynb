{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downloading dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "\n",
    "od.download(\n",
    "    'https://www.kaggle.com/datasets/shariful07/student-mental-health/data')\n",
    "\n",
    "dataset = pd.read_csv(\"student-mental-health\\\\Student Mental health.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping timestamp column\n",
    "dataset = dataset.drop(\"Timestamp\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "dataset.rename(columns={'OldColumnName1': 'NewColumnName1', 'OldColumnName2': 'NewColumnName2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing gender column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "# Filling empty cells with value \"Female\"\n",
    "dataset['Choose your gender'].fillna('Female', inplace=True)\n",
    "dataset['Choose your gender'] = label_encoder.fit_transform(\n",
    "    dataset['Choose your gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing age column\n",
    "mean_age = dataset['Age'].mean()\n",
    "dataset['Age'].fillna(mean_age, inplace=True)\n",
    "# Round the mean value to the nearest integer (optional)\n",
    "mean_age = round(mean_age)\n",
    "# Convert the 'Age' column to integers\n",
    "dataset['Age'] = dataset['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing course column\n",
    "\n",
    "import openai\n",
    "import time\n",
    "\n",
    "# Set your OpenAI GPT-3 API key\n",
    "openai.api_key = ''\n",
    "\n",
    "\n",
    "def categorize_course_with_gpt3(course):\n",
    "    # Construct a prompt for GPT-3 to perform a web search\n",
    "    prompt = f\"Select the field of this course {course} from these given fields. Do not reply anything else than the given feilds. Reply only the strings of field:\\n\" \\\n",
    "             \"Arts and Humanities\\n\" \\\n",
    "             \"Social Sciences\\n\" \\\n",
    "             \"Natural Sciences\\n\" \\\n",
    "             \"Engineering and Technology\\n\" \\\n",
    "             \"Health Sciences\\n\" \\\n",
    "             \"Business and Economics\\n\" \\\n",
    "             \"Law\\n\" \\\n",
    "             \"Religious Studies\\n\" \\\n",
    "             \"Agriculture and Environmental Studies\\n\" \\\n",
    "             \"Interdisciplinary Studies\\n\" \\\n",
    "             \"Communication and Media\\n\" \\\n",
    "             \"Computer and Information Sciences\\n\" \\\n",
    "             \"Physical Education and Sports Sciences\\n\" \\\n",
    "             \"Mathematics and Statistics\\n\" \\\n",
    "             \"Public Policy and Administration\\n\" \\\n",
    "             \"Interdisciplinary and General Education\\n\"\n",
    "\n",
    "    # Make an API call to GPT-3 using the chat completion endpoint\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=150  # Adjust as needed\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "# Set the rate limit variables\n",
    "requests_limit = 3\n",
    "wait_time = 60\n",
    "\n",
    "# Iterate over the DataFrame and update values\n",
    "for index, row in dataset.iterrows():\n",
    "    current_value = row['What is your course?']\n",
    "    if pd.notna(current_value):\n",
    "        updated_value = categorize_course_with_gpt3(current_value)\n",
    "        dataset.at[index, 'What is your course?'] = updated_value\n",
    "        print(updated_value)\n",
    "    else:\n",
    "        dataset.at[index, 'What is your course?'] = \"General Studies\"\n",
    "        print(\"General Studies\")\n",
    "\n",
    "    # Check if 3 requests have been made and introduce a wait\n",
    "    if (index + 1) % requests_limit == 0 and index != 0:\n",
    "        print(f\"Waiting for {wait_time} seconds...\")\n",
    "        time.sleep(wait_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing course column -- continue\n",
    "\n",
    "dataset['What is your course?'] = label_encoder.fit_transform(\n",
    "    dataset['What is your course?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Your current year of Study column\n",
    "\n",
    "label_mapping_year = {\n",
    "    \"year 1\": 0,\n",
    "    \"year 2\": 1,\n",
    "    \"year 3\": 2,\n",
    "    \"year 4\": 3\n",
    "}\n",
    "\n",
    "# Clean up column values by converting to lowercase and removing leading and trailing spaces\n",
    "dataset['Your current year of Study'] = dataset['Your current year of Study'].str.lower().str.strip()\n",
    "\n",
    "# Apply label encoding using a for loop with a check for matching characters\n",
    "dataset['Your current year of Study'] = [next((label_mapping_year[label] for label in label_mapping_year if all(char in year for char in label)), None) for year in dataset['Your current year of Study']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing course CGPA column\n",
    "\n",
    "label_mapping = {\n",
    "    \"0-1.99\": 0,\n",
    "    \"2.00-2.49\": 1,\n",
    "    \"2.50-2.99\": 2,\n",
    "    \"3.00-3.49\": 3,\n",
    "    \"3.5-4.00\": 4\n",
    "}\n",
    "\n",
    "# Clean up column values by removing leading and trailing spaces\n",
    "dataset['What is your CGPA?'] = dataset['What is your CGPA?'].str.strip()\n",
    "\n",
    "# Apply label encoding using a for loop with a check for matching characters\n",
    "dataset['What is your CGPA?'] = [next((label_mapping[label] for label in label_mapping if all(\n",
    "    char in cgpa for char in label)), None) for cgpa in dataset['What is your CGPA?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing martial status column\n",
    "\n",
    "dataset['Marital status'] = label_encoder.fit_transform(\n",
    "    dataset['Marital status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Do you have Depression? column\n",
    "\n",
    "dataset['Do you have Depression?'] = label_encoder.fit_transform(\n",
    "    dataset['Do you have Depression?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Do you have Anxiety? column\n",
    "\n",
    "dataset['Do you have Anxiety?'] = label_encoder.fit_transform(\n",
    "    dataset['Do you have Anxiety?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Do you have Panic attack? column\n",
    "\n",
    "dataset['Do you have Panic attack?'] = label_encoder.fit_transform(\n",
    "    dataset['Do you have Panic attack?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Did you seek any specialist for a treatment? column\n",
    "\n",
    "dataset['Did you seek any specialist for a treatment?'] = label_encoder.fit_transform(\n",
    "    dataset['Did you seek any specialist for a treatment?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"new_file.csv\")\n",
    "sns.pairplot(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "dataset.sort_values(by= \"Age\" ,inplace=True)\n",
    "plt.figure(dpi=200)\n",
    "fig = px.bar(dataset, x=\"Age\", y=\"What is your course?\", orientation='h',color='Do you have Depression?')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdataset = pd.read_csv(\"new_file.csv\")\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, specs=[[{}, {}]], shared_xaxes=True,\n",
    "                    shared_yaxes=False, vertical_spacing=0.001)\n",
    "\n",
    "x1 = [18,19,20,21,22,23,24]\n",
    "\n",
    "fig.append_trace(go.Bar(\n",
    "    x=tempdataset[\"Do you have Depression?\"],\n",
    "    y=x1,\n",
    "    marker=dict(\n",
    "        color='rgba(50, 171, 96, 0.6)',\n",
    "        line=dict(\n",
    "            color='rgba(20, 10, 56, 1.0)',\n",
    "            width=0),\n",
    "    ),\n",
    "    name='Depression across the ages',\n",
    "    orientation='h',\n",
    "), 1, 1)\n",
    "\n",
    "fig.append_trace(go.Scatter(\n",
    "    x=tempdataset[\"Do you have Panic attack?\"], y=x1,\n",
    "    mode='lines+markers',\n",
    "    line_color='rgb(40, 0, 128)',\n",
    "    name='Panic Attacks',\n",
    "), 1, 2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Major depression and Panic Attacks',\n",
    "    yaxis=dict(\n",
    "        showgrid=False,\n",
    "        showline=False,\n",
    "        showticklabels=True,\n",
    "        domain=[0, 0.85],\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        showgrid=False,\n",
    "        showline=True,\n",
    "        showticklabels=False,\n",
    "        linecolor='rgba(102, 102, 102, 0.8)',\n",
    "        linewidth=5,\n",
    "        domain=[0, 0.85],\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        zeroline=False,\n",
    "        showline=False,\n",
    "        showticklabels=True,\n",
    "        showgrid=True,\n",
    "        domain=[0, 0.45],\n",
    "    ),\n",
    "    xaxis2=dict(\n",
    "        zeroline=False,\n",
    "        showline=False,\n",
    "        showticklabels=True,\n",
    "        showgrid=True,\n",
    "        domain=[0.47, 1],\n",
    "        side='top',\n",
    "        dtick=10000,\n",
    "    ),\n",
    "    legend=dict(x=0.029, y=1.038, font_size=10),\n",
    "    margin=dict(l=100, r=20, t=70, b=70),\n",
    "    paper_bgcolor='rgb(248, 248, 255)',\n",
    "    plot_bgcolor='rgb(248, 248, 255)',\n",
    ")\n",
    "\n",
    "annotations = []\n",
    "\n",
    "\n",
    "# Adding labels\n",
    "for ydn, yd, xd in zip(tempdataset[\"Do you have Panic attack?\"], tempdataset[\"Do you have Depression?\"], x1):\n",
    "    # labeling the scatter savings\n",
    "    annotations.append(dict(xref='x2', yref='y2',\n",
    "                            y=xd, x=ydn+10,\n",
    "                            text='{:,}'.format(ydn) + '%',\n",
    "                            font=dict(family='Arial', size=10,\n",
    "                                      color='rgb(128, 0, 128)'),\n",
    "                            showarrow=False))\n",
    "    # labeling the bar net worth\n",
    "    annotations.append(dict(xref='x1', yref='y1',\n",
    "                            y=xd, x=yd+10 ,\n",
    "                            text=str(yd) + '%',\n",
    "                            font=dict(family='Arial', size=10,\n",
    "                                      color='rgb(50, 171, 96)'),\n",
    "                            showarrow=False))\n",
    "# Source\n",
    "annotations.append(dict(xref='paper', yref='paper',\n",
    "                        x=-0.2, y=-0.109,\n",
    "                        text=\"Mental health visualization\",\n",
    "                        font=dict(family='Arial', size=20, color='rgb(150,150,150)'),\n",
    "                        showarrow=False))\n",
    "\n",
    "fig.update_layout(annotations=annotations)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\"Appetite change\", \"Average across symptoms\", \"Depressed mood\", \"Difficulty concentrating\", \"Loss of interest\",\n",
    "    \"Low energy\", \"Low self-esteem\", \"Psychomotor agitation\", \"Psychomotor agitation\", \"Sleep problems\", \"Suicidal ideation\"]\n",
    "\n",
    "fig = go.Figure()\n",
    "# Create and style traces\n",
    "fig.add_trace(go.Scatter(x=x, y=df3[\"Nearly every day\"], name='Nearly every day',\n",
    "                         line=dict(color='firebrick', width=4)))\n",
    "fig.add_trace(go.Scatter(x=x, y=df3[\"More than half the days\"], name = 'More than half the days',\n",
    "                         line=dict(color='royalblue', width=4)))\n",
    "fig.add_trace(go.Scatter(x=x, y=df3[\"Several days\"], name='Several days',\n",
    "                         line=dict(color='black', width=4,\n",
    "                              dash='dashdot') # dash options include 'dash', 'dot', and 'dashdot'\n",
    "))\n",
    "\n",
    "# Edit the layout\n",
    "fig.update_layout(title='Depressive symptoms across us population',\n",
    "                   xaxis_title='Entity',\n",
    "                   yaxis_title='Types of days')\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize = (16,5))\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(20)\n",
    "plt.subplots_adjust(wspace = 0)\n",
    "fig.suptitle('Mental Health Disorder in Tech (in the past)', fontsize = 25, y=1.08)\n",
    "\n",
    "# Pie Chart (Past)\n",
    "all_techs_past = imp_data[imp_data['tech_flag'] == 1]['mh_disorder_current'].count()\n",
    "no_past = imp_data[(imp_data['tech_flag'] == 1) & (imp_data['mh_disorder_past'] == 'No')]['mh_disorder_past'].count()\n",
    "yes_past = imp_data[(imp_data['tech_flag'] == 1) & (imp_data['mh_disorder_past'] == 'Yes')]['mh_disorder_past'].count()\n",
    "maybe_past = imp_data[(imp_data['tech_flag'] == 1) & (imp_data['mh_disorder_past'] == 'Maybe')]['mh_disorder_past'].count()\n",
    "\n",
    "labels = 'No', 'Yes', 'Maybe'\n",
    "sizes = [no_past/all_techs_past, yes_past/all_techs_past, maybe_past/all_techs_past]\n",
    "colors = ['#73C6B6', '#F0B27A', '#7FB3D5']\n",
    "explode = (0, 0.03, 0)  # explode 1st slice\n",
    "\n",
    "ax2.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=False, startangle=140)\n",
    "ax2.axis('equal')\n",
    "ax2.set_title('Overall MH prop% (PAST)', pad = 20, fontsize = 20)\n",
    "\n",
    "# Barchart (Past)\n",
    "sns.countplot(x = imp_data[imp_data['tech_flag'] == 1]['country_live'], hue = imp_data['mh_disorder_past'], ax = ax1)\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=15, ha=\"right\")\n",
    "ax1.set_title('MH by Countries (PAST)', pad = 20, fontsize = 20)\n",
    "ax1.set_xlabel('Country', fontsize = 18)\n",
    "ax1.set_ylabel('Count', fontsize = 18)\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "chart = sns.countplot(x = 'Age', data = dataset[dataset['Do you have Depression?'] == 2])\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=45, horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat= dataset.corr()\n",
    "plt.figure(figsize=(10,10))  \n",
    "sns.heatmap(corrmat,annot=True, cmap=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.to_csv('new_file.csv', index=False)\n",
    "\n",
    "tempdataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.1'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(\n",
    "    tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.50 %\n",
      "Standard Deviation: 11.18 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saif_\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning:\n",
      "\n",
      "The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
